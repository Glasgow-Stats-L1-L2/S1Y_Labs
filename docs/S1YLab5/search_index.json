[["index.html", "S1Y Lab 5 Welcome to Lab 5 Intended Learning Outcomes Credit where credit is due", " S1Y Lab 5 Welcome to Lab 5 Intended Learning Outcomes This lab will investigate the ways in which the statistics from a random sample can serve to make inference and test hypotheses about the true parameter in the larger population. We will explore here inference methods for categorical data. Before we begin however, let's revisit the difference between categorical and numerical data. Categorical Data: Data where an observation can belong to one of a certain fixed number of categories or groups. For example, someone's bloodtype. Your bloodtype can be one of A, B, AB or O. Numerical Data: Data in the form of numbers; rather than being defined as a member of some group or category. It also must make sense for calculations to be performed on those numbers, such as adding them or taking averages of them. This is important, for example a phone number is a number but it doesn't make sense to add phone numbers together. An example of numerical data is your height. It's measured with a number you can perform calculations directly on such as averages. Another example would be a count of the number of patients seen at a GP Surgery in a day. The material within this lab has been based on OpenLearn Chapters 6 OpenIntro Page 206. Feel free to refer back to the materials to help you within this lab. Credit where credit is due The labs in S1Y/Z are a derivative of the labs on the OpenIntro Statistics website by the OpenIntro team used under a Creative Commons Attribution-ShareAlike 4.0 International License. Some of the artwork used is by @allison_horst "],["data.html", "Data", " Data In this Lab, we will explore and visualise the data using the tidyverse suite of packages and perform statistical inference. library(tidyverse) We will be looking at data from the Youth Risk Behaviour Surveillance System (YRBSS) survey, which uses data from American high school students to help discover health patterns. The dataframe is called yrbss and is part of the openintro package. We can access the dataframe and make a version with missing values removed using this code. library(openintro) yrbss &lt;- na.omit(yrbss) The dataframe yrbss contains 13 variables: • age: Age of the student. • gender: Gender of the student. • grade: School grade of the student. • hispanic: If the student is hispanic, or not. • race: Ethnicity of the student. • height: Height of the student, in metres. • weight: Weight of the student, in kilograms. • helmet_12m: How often the student wore a helmet while riding a bike in the last 12 months. • text_while_driving_30d: How many days out of the last 30 did the the student text while driving. • physically_active_7d: How many days out of the last 7 was the student physically active for at least an hour. • hours_tv_per_school_day: How many hours of TV does the student typically watch on a school night. • strength_training_7d: How many days out of the last 7 did the student lift weights. • school_night_hours_sleep: How many hours of sleep does the student typically get on a school night? First of all, it is always a good idea to look at the dataset you are working with to get a good sense of what it looks like, and the different types of data you may have, e.g. categorical or numerical. Run the code below to look at the first 6 rows of data and the structure of it. head(yrbss) str(yrbss) Recall from Lab 1, head() is a function where you put in it's brackets the name of the data frame, in this case yrbss, and it gives you the first 6 lines of that data to look at. Again recall from Lab 1 str() is another function where you put the name of the data frame in the brackets, and this time it gives you the number of observations and the number of variables you have, the types of those variables e.g. \"int\" for an integer, \"num\" for a number and \"chr\" for a string of characters, as well as the first few values of each variable. How many observations/rows are there in the entire data set? Hint Look at the result of the str() function. "],["inference-for-categorical-data.html", "Inference for Categorical Data", " Inference for Categorical Data Figure 1: Blood type, an example of Categorical Data The code below is an example of presenting some sort of summary of the data frame yrbss. Specifically, the goal is to find out how many students there are in each of the different categories for how much sleep they typically get on a school night. yrbss %&gt;% group_by(school_night_hours_sleep) %&gt;% summarize(count = n()) You've seen both group_by() and summarize() functions in Lab 1 but it's worth having a refresher. First, you type the name of the overall dataframe you want to look at. In this case, yrbss. Then group the data by one of your variables using the group_by() function. The hours of sleep a night variable school_night_hours_sleep has been chosen but you could group by whichever variable you want based on the question of interest. Then summarise the grouped data using the summarize() function. You have to give your summary a name, in this instance we called it count but you could call it whatever you like. Finally, since we want to find the counts of how many students get different amounts of sleep, we use the n() function which refers to the counts. When you run the above code, you will see this output: ## # A tibble: 7 × 2 ## school_night_hours_sleep count ## &lt;chr&gt; &lt;int&gt; ## 1 10+ 174 ## 2 5 1023 ## 3 6 1845 ## 4 7 2417 ## 5 8 1799 ## 6 9 496 ## 7 &lt;5 597 Exercise 1 Adapt the code from the previous example to find out what the counts are within each category for the amount of days the students have texted while driving within the past 30 days. Look back to the information about the data frame yrbss to find the name of the variable you want. Hint Use the group_by() and summarize() functions. The variable you want to group by is called text_while_driving_30d in yrbss. Solution yrbss %&gt;% group_by(text_while_driving_30d) %&gt;% summarize(count = n()) ## # A tibble: 8 × 2 ## text_while_driving_30d count ## &lt;chr&gt; &lt;int&gt; ## 1 0 3137 ## 2 1-2 658 ## 3 10-19 281 ## 4 20-29 224 ## 5 3-5 347 ## 6 30 583 ## 7 6-9 230 ## 8 did not drive 2891 Which category has the highest count? 0 of the last 30 days The students that didn't drive 6-9 of the last 30 days All 30 of the last 30 days. Hint Look for the highest count value from the grouped by summary. Exercise 2 Create a subset, called no_helmet, of the data frame yrbss using the code below. This subset no_helmet contains only the students that never wore a helmet, and a new variable text_every_day which is \"yes\" the student has texted and drove every day of the last 30 or \"no\" if they haven't. no_helmet &lt;- yrbss %&gt;% filter(helmet_12m == &quot;never&quot;) no_helmet &lt;- no_helmet %&gt;% mutate(text_every_day = ifelse(text_while_driving_30d == &quot;30&quot;, &quot;yes&quot;, &quot;no&quot;)) Again you've seen the filter() and mutate() functions in Lab 1. In the first 2 lines of the above code, we use the filter() function to subset yrbss and extract only some data, based on some rule. In this case we want only the students who never wore a helmet, i.e. the students for whom the helmet_12m variable equals \"never\". We stored this new subset of the data in the no_helmet object, but you could of course call it whatever you like. The &lt;- basically just tells R to store this new subset in an object called \"no_helmet\". In the second part of the code, we create the new variable text_every_day. no_helmet &lt;- no_helmet refers to updating the existing dataset \"no_helmet\" rather than creating an entirely new one. Then, (%&gt;%), we use the mutate() function to create a new variable based on some rule and add it to the dataset no_helmet. The rule here is to assign \"yes\" for every student whom texting while driving variable equals 30 and 0 otherwise. Find the proportion of students who have texted while driving every day in the past 30 days among those who never wore helmets. Hint We first want to group_by() the text_every_day variable just created, then count the number of students in each category and finally calculate the proportion of students for whom text_every_day is \"yes\" out of everyone who is the no_helmet dataset. Solution no_helmet %&gt;% group_by(text_every_day) %&gt;% summarize(count = n()) %&gt;% mutate(prop=count/sum(count)) ## # A tibble: 2 × 3 ## text_every_day count prop ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 no 4012 0.924 ## 2 yes 332 0.0764 What percentage of students have texted while driving every day in the last 30 days, and never wore a bike helmet? (to 2 decimal places) % "],["inference-on-proportions.html", "Inference on Proportions", " Inference on Proportions The Center for Disease Control and Prevention seeks to report the proportion of people who have texted while driving each day for the past 30 days. To do this, you can answer the question, \"What proportion of people in your sample reported that they have texted while driving each day for the past 30 days?\" with a sample statistic; while the question \"What proportion of people on earth have texted while driving each day for the past 30 days?\" is answered with an estimate of the population parameter. The inferential tools for estimating population proportion are: confidence intervals and hypothesis tests. Calculating Confidence Intervals (CIs) for proportions Recall from page 181 of OpenIntro that the 95% Confidence Interval for a proportion is given by \\[\\hat{p} \\pm 1.96*SE\\] where \\(SE = \\textrm{Standard Error} = \\sqrt\\frac{p(1-p)}{n}\\). The standard error is estimated by replacing \\(p\\) with its estimate \\(\\hat{p}\\). Here \\(n\\) is the sample size, 4344 in the yrbss data, and the critical value \\(z\\) equals 1.96 for the standard 95% confidence interval. We can use R as a calculator with * being the multiplying operator, / being the dividing operator and sqrt() being the square root operator. Exercise 3 Construct a confidence interval for the proportion of non-helmet wearing students (in the general population) who have texted while driving each day for the past 30 days. Hint First calculate a point estimate p for the proportion of non-helmet wearing students (in the general populaton) who have texted while driving each day (look at the output from Exercise 2 for the relevant numbers). The upper and lower bounds can then be calculated as p + 1.96*sqrt(p*(1-p)/n) and p - 1.96*sqrt(p*(1-p)/n). Solution p &lt;- 332/(332+4012) n &lt;- 332+4012 upper.bound &lt;- p + 1.96*sqrt(p*(1-p)/n) lower.bound &lt;- p - 1.96*sqrt(p*(1-p)/n) lower.bound ## [1] 0.06852646 upper.bound ## [1] 0.08432805 What could you interpret from this confidence interval? We are 95% confident the true proportion of non-helmet wearing students that texted while driving in all 30 of the previous 30 days is exactly 0.076, since this is inside the confidence interval. We are 95% confident the true proportion of non-helmet wearing students that texted while driving in all 30 of the previous 30 days is somewhere between 0.069 and 0.084. We are 90% confident the true proportion of non-helmet wearing students that texted while driving in all 30 of the previous 30 days is somewhere between 0.069 and 0.084. The proportion we calculated in outside of the interval calculated here, therefore we cannot make any valid interpretations. Hint Look in the textbook if you need a refresher on interpreting confidence intervals. Margin of Error Recall that the margin of error is half the width of a confidence interval. Referring back to the previous question, the margin of error is simply \\[ME = z*SE = z \\sqrt\\frac{p(1-p)}{n}\\] and for a standard 95% CI, \\[= 1.96 \\sqrt\\frac{p(1-p)}{n}\\] Exercise 4 What is the margin of error for the estimate of the proportion of non-helmet wearers that have texted while driving each day for the past 30 days based on this survey? What is the margin or error for the proportion in question? (to 3 decimal places) Hint #calculate the margin of error in R using the code 1.96*sqrt(p*(1-p)/n) Exercise 5 Using the same method as seen above, repeat the process of constructing a confidence interval for the proportion of students who never wore a bike helmet and Had less than 5 hours sleep, then Strength trained every day, instead of texted while driving every day of the past 30 days. You should construct two confidence intervals, one for a) and one for b). You will need to answer the problem in two steps. Firstly, to construct a new \"yes\" or \"no\" variable, by adapting some code above and considering which variable to change and which category of that variable to change also i.e. what the == part equals. Secondly, you will need to construct a confidence interval in the same way as above, by working out your new \\(p\\) and \\(n\\) values using the same methods as before. Hint We have already created the dataset no_helmet and want to mutate it to add a new variable which indicates whether a student had less than 5 hours sleep (the number of hours slept is shown by the school_night_hours_sleep variable). Then, count the number of \"yes\"'s in this new variable and use this to calculate an estimate of the proportion p. Solution (a) no_helmet &lt;- no_helmet %&gt;% mutate(less5_hours_sleep = ifelse(school_night_hours_sleep == &quot;&lt;5&quot;, &quot;yes&quot;, &quot;no&quot;)) no_helmet %&gt;% group_by(less5_hours_sleep) %&gt;% summarize(count = n()) ## # A tibble: 2 × 2 ## less5_hours_sleep count ## &lt;chr&gt; &lt;int&gt; ## 1 no 4022 ## 2 yes 322 p &lt;- 322/(322+4022) n &lt;- 322+4022 upper.bound &lt;- p + 1.96*sqrt(p*(1-p)/n) lower.bound &lt;- p - 1.96*sqrt(p*(1-p)/n) lower.bound ## [1] 0.06633464 upper.bound ## [1] 0.08191582 Hint Within mutate, change the ifelse() statement to ifelse(physically_active_7d==7, \"yes\", \"no\") to create a new variable in no_helmet that takes the value \"yes\" if a student has strength trained every day for the past 7 days, and \"no\" otherwise. Solution (b) no_helmet &lt;- no_helmet %&gt;% mutate(train_every_day = ifelse(physically_active_7d==7,&quot;yes&quot;,&quot;no&quot;)) no_helmet %&gt;% group_by(train_every_day) %&gt;% summarize(count = n()) ## # A tibble: 2 × 2 ## train_every_day count ## &lt;chr&gt; &lt;int&gt; ## 1 no 3014 ## 2 yes 1330 p &lt;- 1330/(1330+3014) n &lt;- 1330+3014 upper.bound &lt;- p + 1.96*sqrt(p*(1-p)/n) lower.bound &lt;- p - 1.96*sqrt(p*(1-p)/n) lower.bound ## [1] 0.2924632 upper.bound ## [1] 0.3198757 How could you compare the two CI for proportions calculated above? The CI for the proportion of non-helmet wearing strength trainers seems far wider than the CI for the proportion of non-helmet wearing students with less than 5 hours sleep. The proportion of non-helmet wearing strength trainers probably equals the proportion of non-helmet wearing students that gets less than 5 hours sleep. We can make no comparisons between the two groups whatsoever at this stage of the analysis. The proportion of non helmet wearing strength trainers is probably much greater than the proportion of non-helmet wearing people with less than 5 hours sleep, since the CI is far above. Hint Look at where the first proportion's CI ends compared to where the second proportion's CI begins. "],["group-tasks.html", "Group Tasks", " Group Tasks In August of 2012, news outlets ranging from the Washington Post to the Huffington Post ran a story about the rise of atheism in America. The source for the story was a poll that asked people, “Irrespective of whether you attend a place of worship or not, would you say you are a religious person, not a religious person or a convinced atheist?” This type of question, which asks people to classify themselves in one way or another, is common in polling and generates categorical data. Load the atheism data set into your workspace by typing the following code in an Rscript file in your local Rstudio. Feel free to explore the data before completing the following tasks. download.file(&quot;http://www.openintro.org/stat/data/atheism.RData&quot;, destfile = &quot;atheism.RData&quot;) load(&quot;atheism.RData&quot;) How many countries are included with the atheism data set? (Give your answer as a whole number) Task 1 Create a 95% confidence interval for the proportion of Spanish people identify as \"atheist\" in 2005. You will first need to filter the atheism data set by nationality being \"Spain\", and then by the year 2005. Task 2 Create a 95% confidence interval for the proportion of Spanish people identify as \"atheist\" in 2012 using the same method as before. Is there convincing evidence that Spain has seen a change in its atheism index between 2005 and 2012? The two confidence intervals overlap, therefore there is evidence of Spain seeing a change in it's atheism index The two confidence intervals do not overlap, therefore there is no evidence of Spain seeing a change in it's atheism index The two confidence intervals do not overlap, therefore there is evidence of Spain seeing a change in it's atheism index The two confidence intervals overlap, therefore there is no evidence of Spain seeing a change in it's atheism index Task 3 Repeat Tasks 1 and 2 to calculate two 95% confidence intervals for the proportion of Americans who identify as \"atheist\" in 2005 and in 2012. Is there convincing evidence that the USA has seen a change in its atheism index between 2005 and 2012? The two confidence intervals overlap, therefore there is evidence of the USA seeing a change in it's atheism index The two confidence intervals do not overlap, therefore there is no evidence of the USA seeing a change in it's atheism index The two confidence intervals do not overlap, therefore there is evidence of the USA seeing a change in it's atheism index The two confidence intervals overlap, therefore there is no evidence of the USA seeing a change in it's atheism index If in reality there has been no change in the atheism index in any of the countries, in how many of the countries would you expect to detect a change (at a significance level of 0.05) simply by chance? (to the nearest whole number) Hint We need to take the probability of a Type 1 error (rejecting the null hypothesis when \\(H_0\\) is actually true) and times it by 57 (the number of countries within atheism). The probability of a Type 1 error is simply the significance level alpha, in this case, 0.05. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
